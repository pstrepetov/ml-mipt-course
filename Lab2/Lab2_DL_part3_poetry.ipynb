{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh-Im1BnC5dX"
      },
      "source": [
        "## Lab 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeiDURdLC5dg"
      },
      "source": [
        "### Part 3. Poetry generation\n",
        "\n",
        "Let's try to generate some poetry using RNNs. \n",
        "\n",
        "You have several choices here: \n",
        "\n",
        "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
        "\n",
        "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
        "\n",
        "* Some other text source, if it will be approved by the course staff.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading.\n",
        "2. Dictionary generation.\n",
        "3. Data preprocessing.\n",
        "4. Model (neural network) training.\n",
        "5. Text generation (model evaluation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sVdLBOmqC5di"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFuVFCyhC5dj"
      },
      "source": [
        "### Data loading: Shakespeare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-dkQRQ9C5dk"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "bpUgrHWaC5dk",
        "outputId": "562bf083-6b8c-4b85-b873-90d169270742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-25 22:19:00--  https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks/lab02_deep_learning/sonnets.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 119748 (117K) [text/plain]\n",
            "Saving to: ‘sonnets.txt’\n",
            "\n",
            "\rsonnets.txt           0%[                    ]       0  --.-KB/s               \rsonnets.txt         100%[===================>] 116.94K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-02-25 22:19:00 (5.25 MB/s) - ‘sonnets.txt’ saved [119748/119748]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks/lab02_deep_learning/sonnets.txt\n",
        "\n",
        "with open('sonnets.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "    \n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START : TEXT_END]\n",
        "assert len(text) == 2616"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9R1NXCXC5dl"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-L-PSc7cC5dl",
        "outputId": "a120ef78-6879-441f-ecb8-6084c9e9b0d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max length = 63\n",
            "OK!\n"
          ]
        }
      ],
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "\n",
        "text_ = ''.join(text).lower()\n",
        "MAX_LENGTH = max(map(len, text))\n",
        "print(\"max length =\", MAX_LENGTH)\n",
        "\n",
        "assert len(text_) == 100225, 'Are you sure you have concatenated all the strings?'\n",
        "assert not any([x in set(text_) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
        "print('OK!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K83--qlSC5dm"
      },
      "source": [
        "### Data loading: \"Евгений Онегин\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Gsrt3_UC5dn",
        "outputId": "94884717-0af7-49a4-f27a-9614590b7408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-23 23:28:42--  https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt.1’\n",
            "\n",
            "\ronegin.txt.1          0%[                    ]       0  --.-KB/s               \ronegin.txt.1        100%[===================>] 256.37K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-02-23 23:28:42 (7.93 MB/s) - ‘onegin.txt.1’ saved [262521/262521]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
        "    \n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "    \n",
        "text = [x.replace('\\t\\t', '') for x in text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gzvVfAbC5do"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJOPI9TiC5dp",
        "outputId": "65b4f2df-ecaf-495f-e4a9-60b9224dc49c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max length = 63\n"
          ]
        }
      ],
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "\n",
        "text_ = ''.join(text).lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dictionary generation"
      ],
      "metadata": {
        "id": "q6gLTqQRj-jt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i84cbN86C5dr"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "tZaQQRiSC5dr"
      },
      "outputs": [],
      "source": [
        "out = [char for char in text_]\n",
        "tokens = sorted(set(out))\n",
        "tokens.append('_')\n",
        "num_tokens = len(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSnD3pacC5ds"
      },
      "source": [
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "collapsed": true,
        "id": "jd0v3O4VC5ds",
        "outputId": "f0b19b00-381b-422e-b433-7c80e290ec9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, ':': 9, ';': 10, '?': 11, 'a': 12, 'b': 13, 'c': 14, 'd': 15, 'e': 16, 'f': 17, 'g': 18, 'h': 19, 'i': 20, 'j': 21, 'k': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'q': 28, 'r': 29, 's': 30, 't': 31, 'u': 32, 'v': 33, 'w': 34, 'x': 35, 'y': 36, 'z': 37, '_': 38}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: ',', 7: '-', 8: '.', 9: ':', 10: ';', 11: '?', 12: 'a', 13: 'b', 14: 'c', 15: 'd', 16: 'e', 17: 'f', 18: 'g', 19: 'h', 20: 'i', 21: 'j', 22: 'k', 23: 'l', 24: 'm', 25: 'n', 26: 'o', 27: 'p', 28: 'q', 29: 'r', 30: 's', 31: 't', 32: 'u', 33: 'v', 34: 'w', 35: 'x', 36: 'y', 37: 'z', 38: '_'}\n"
          ]
        }
      ],
      "source": [
        "# dict <index>:<char>\n",
        "token_to_idx = {token: idx for idx, token in enumerate(tokens)}\n",
        "print(token_to_idx)\n",
        "# dict <char>:<index>\n",
        "idx_to_token = dict((v,k) for k,v in token_to_idx.items())\n",
        "print(idx_to_token)\n",
        "\n",
        "for i in range(num_tokens):\n",
        "    assert token_to_idx[tokens[i]] == i, \"token identifier must be it's position in tokens list\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing (Shakespeare)"
      ],
      "metadata": {
        "id": "NJqBZiON0QHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "sonnets_ = re.split('\\n\\n', text_)\n",
        "sonnets_ = sonnets_[0::2]\n",
        "print(len(sonnets_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opwQmDktwUUr",
        "outputId": "73c66179-899a-4f59-a2c4-eb04bffd9c61"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sonnets = [sonnet + '\\n' for sonnet in sonnets_]\n",
        "print(sonnets[1:2])\n",
        "print(max(map(len,sonnets)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZuA7XIb1aX8",
        "outputId": "875c685d-c1fd-4c30-f4ff-bab01f7ebafe"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"  when forty winters shall besiege thy brow,\\n  and dig deep trenches in thy beauty's field,\\n  thy youth's proud livery so gazed on now,\\n  will be a tatter'd weed of small worth held:\\n  then being asked, where all thy beauty lies,\\n  where all the treasure of thy lusty days;\\n  to say, within thine own deep sunken eyes,\\n  were an all-eating shame, and thriftless praise.\\n  how much more praise deserv'd thy beauty's use,\\n  if thou couldst answer 'this fair child of mine\\n  shall sum my count, and make my old excuse,'\\n  proving his beauty by succession thine!\\n    this were to be new made when thou art old,\\n    and see thy blood warm when thou feel'st it cold.\\n\"]\n",
            "709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ2wPJ8gC5ds"
      },
      "source": [
        "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEajQRirC5dt"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEdXwR2oC5dt"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def to_matrix(\n",
        "    text, max_len=None, pad=token_to_idx['_'], dtype='int32', batch_first=True\n",
        "    ):\n",
        "    \"\"\"Casts a list of texts into rnn-digestable matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, text))\n",
        "    text_ix = np.zeros([len(text), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(text)):\n",
        "        line_ix = [token_to_idx[c] for c in text[i]][:max_len]\n",
        "        text_ix[i, :len(line_ix)] = line_ix\n",
        "\n",
        "        \n",
        "    if not batch_first: # convert [batch, time] into [time, batch]\n",
        "        text_ix = np.transpose(text_ix)\n",
        "\n",
        "    return text_ix"
      ],
      "metadata": {
        "id": "x3gpyy1HgRTe"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(to_matrix(sonnets[:2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pulmfYHLXlq",
        "outputId": "9b60883d-cdcb-464e-ae73-62d4ec719343"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  1 17 ... 38 38 38]\n",
            " [ 1  1 34 ... 15  8  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_UNITS = 256\n",
        "NUM_TOKENS = len(tokens) #39\n",
        "MAX_LEN = max(map(len,sonnets)) #709\n",
        "BATCH_LEN = 32"
      ],
      "metadata": {
        "id": "iDSjgqj4Q0ml"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CharRNNCell(nn.Module):\n",
        "    \"\"\"\n",
        "    Implement the scheme above as torch module\n",
        "    \"\"\"\n",
        "    def __init__(self, num_tokens=NUM_TOKENS, embedding_size=MAX_LEN, rnn_num_units=NUM_UNITS):\n",
        "        super(self.__class__,self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "        \n",
        "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
        "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
        "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"\n",
        "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
        "        We'll call it repeatedly to produce the whole sequence.\n",
        "        \n",
        "        :param x: batch of character ids, containing vector of int64\n",
        "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
        "        \"\"\"\n",
        "        # get vector embedding of x\n",
        "        x_emb = self.embedding(x)\n",
        "        \n",
        "        # compute next hidden state using self.rnn_update\n",
        "        x_and_h = torch.cat([x_emb, h_prev], dim=-1)\n",
        "        h_next = self.rnn_update(x_and_h)\n",
        "        h_next = torch.tanh(h_next)\n",
        "        \n",
        "        assert h_next.size() == h_prev.size()\n",
        "        \n",
        "        #compute logits for next character probs\n",
        "        logits = self.rnn_to_logits(h_next)\n",
        "        \n",
        "        return h_next, logits\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
        "        return torch.zeros(batch_size, self.num_units, requires_grad=True)"
      ],
      "metadata": {
        "id": "uagwHcq2Id7n"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rnn_loop(char_rnn, batch_ix):\n",
        "    \"\"\"\n",
        "    Computes log P(next_character) for all time-steps in names_ix\n",
        "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
        "    \"\"\"\n",
        "    batch_size, max_length = batch_ix.size()\n",
        "    hid_state = char_rnn.initial_state(batch_size)\n",
        "    logits = []\n",
        "\n",
        "    for x_t in batch_ix.transpose(0,1):\n",
        "        hid_state, logits_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
        "        logits.append(logits_next)\n",
        "        \n",
        "    return torch.stack(logits, dim=1)"
      ],
      "metadata": {
        "id": "wYVcT0u4LafF"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "char_rnn = CharRNNCell()\n",
        "opt = torch.optim.Adam(char_rnn.parameters())\n",
        "loss_func = nn.CrossEntropyLoss(ignore_index=token_to_idx['_'])\n",
        "\n",
        "history = []"
      ],
      "metadata": {
        "id": "Kqu3aKDqMMOG"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "    batch_ix = to_matrix(sample(sonnets, BATCH_LEN), max_len=MAX_LEN)\n",
        "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "    \n",
        "    logits_seq = rnn_loop(char_rnn, batch_ix)\n",
        "    \n",
        "    predictions_logits = logits_seq[:, :-1]\n",
        "    actual_next_tokens = batch_ix[:, 1:]\n",
        "\n",
        "    loss = loss_func(\n",
        "    predictions_logits.reshape((-1, num_tokens)),\n",
        "    actual_next_tokens.reshape(-1)\n",
        "    )\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    \n",
        "    opt.zero_grad()\n",
        "    \n",
        "    history.append(loss.data.numpy())\n",
        "    if (i+1)%100==0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history,label='loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.suptitle('Loss per epoch')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "metadata": {
        "id": "Jky7XT4ekutg",
        "outputId": "1b57fd9f-1063-4ae2-f500-7b195d1886d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zma7iAdGC5du"
      },
      "source": [
        "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "xsQJUVV1C5du"
      },
      "outputs": [],
      "source": [
        "def generate_sample(char_rnn, seed_phrase='a', max_length=MAX_LEN, temperature=1.0):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "    \n",
        "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
        "    hid_state = char_rnn.initial_state(batch_size=1)\n",
        "    \n",
        "    #feed the seed phrase, if any\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
        "    \n",
        "    #start generating\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        hid_state, logits_next = char_rnn(x_sequence[:, -1], hid_state)\n",
        "        p_next = F.softmax(logits_next / temperature, dim=-1).data.numpy()[0]\n",
        "        \n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(num_tokens, p=p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "\n",
        "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_poem(model, temperature=1.0, seed='away'):\n",
        "    for i in range(4):\n",
        "        poem = generate_sample(model, seed_phrase=seed, temperature=temperature)\n",
        "        print(poem)\n",
        "        print('\\n')"
      ],
      "metadata": {
        "id": "ktEE5vBjpzuD"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_poem(char_rnn, 1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPMtpYOfM8A3",
        "outputId": "b19be2ae-1423-4a2e-9472-93281c41f798"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "away;\n",
            "  these doth the frister'd new large we thixh all here of my best canst before\n",
            "  my soble despectime;\n",
            "  with my dearest-in of your silen thee his fige.\n",
            "  no, no hold depent,\n",
            "  and all thy bath thee, kilive there;\n",
            "  save seen\n",
            "  passivion doth disgrabson thy lacklawe to the growing than every chilate.'\n",
            "    thou that were base mortard best of my love be fresh?\n",
            "    me, yet, but the priity,\n",
            "  and in dupit eat'st by yourself with sickly not thy looks.\n",
            "    yet then lose, and i lo, of the world-time's might that it with blend;\n",
            "    'tis myself eyes back she that best want no pent,\n",
            "  the daises love debady them nightly chesting,\n",
            "  or wonceat is trifles blood i his lett\n",
            "  fell mine own larse, nor charge d\n",
            "\n",
            "\n",
            "away, being your fairs of their part,\n",
            "  and true,'s usest can all to grow.\n",
            "    that they see anst yet alone.\n",
            "    when thy compicic refeasing your well;\n",
            "    then to live.\n",
            "    but love thy presers that it win of memory advance thou art mine eye i am shadows live?\n",
            "    and did needs never love-cross, where would be farthand i be such worst of evil thy wanting of my wook shours\n",
            "  so thy love and thyments my graves i singer by thy self all the art,\n",
            "  that his summer's ride;\n",
            "  say write of the fiew,\n",
            "  those stapt ever, black like.\n",
            "  the iwleth,\n",
            "  like short,\n",
            "  why have where that feed, make rare.\n",
            "  do be set,\n",
            "    all all my contrilly behind;\n",
            "  hath love, will be fair, me, to shape life the confest.\n",
            "    yet \n",
            "\n",
            "\n",
            "away, to behold.\n",
            "  of golden keep\n",
            "  when thou that see thou thy sight;\n",
            "  and for waste to anothed or whom i an one tyrantest,\n",
            "  to all alone of thee new;\n",
            "  times should acquainst this my sheller place:\n",
            "  mine own change;\n",
            "  those hour:\n",
            "  but to shopping in the handself, title thou my there,\n",
            "  as clove thyself deight\n",
            "  in my heart without be blisses me bow,\n",
            "    and this mines that with tyrann'd,\n",
            "  to time day, be antingal fair,\n",
            "  untruth niggard.\n",
            "  that i may thus fierit eyes i letter, who should long me.\n",
            "    o! for the madness light;\n",
            "  for you dost is shall both shows though desire.\n",
            "    so from your jolding with thy face defelse.\n",
            "    no! wish should he heart to time; ply;\n",
            "  being bounting self, but to\n",
            "\n",
            "\n",
            "away,\n",
            "  that mine eye of this green beauty's cold on none.\n",
            "  thy wome might thy self counts o't if thou art be to this is of shame:\n",
            "  he out thy 'will.\n",
            "  not be raugh'd when their wirth, though my mistress' canspiep\n",
            "  as truft'st him to my sweet leaves fault,\n",
            "  making the heart:\n",
            "  for where;\n",
            "    how all my sin thee more self all overounds of my,\n",
            "  all in eyes best in the eye is fairest tough, or mine eye life, on shame:\n",
            "  for their toulds, found of encerane.\n",
            "  so surledance be,--for all appare,\n",
            "  thou miner war notly news these cannot thou art yous gift thou art my heacted bost lore wail the brand praise what is unfile's hearts save, that my hate,\n",
            "  when thou being from thought when i not away,\n",
            "  and\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7NZ1ZpUC5dv"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharLSTMLoop(nn.Module):\n",
        "    def __init__(self, num_tokens=NUM_TOKENS, emb_size=MAX_LEN, lstm_num_units=NUM_UNITS, num_layers=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.num_units = lstm_num_units\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.lstm = nn.LSTM(emb_size, lstm_num_units, num_layers=num_layers, batch_first=True)\n",
        "        self.hid_to_logits = nn.Linear(lstm_num_units, num_tokens)\n",
        "    \n",
        "    def forward(self, x, state):\n",
        "        input = self.emb(x)\n",
        "        output, state = self.lstm(input, state)\n",
        "        next_logits = self.hid_to_logits(output)\n",
        "\n",
        "        return state, next_logits\n",
        "\n",
        "    def initial_state(self, batch_size):\n",
        "        return (torch.zeros(self.num_layers, batch_size, self.num_units, requires_grad=True),\n",
        "                torch.zeros(self.num_layers, batch_size, self.num_units, requires_grad=True))\n",
        "\n",
        "model_lstm = CharLSTMLoop(emb_size=64)\n",
        "opt = torch.optim.Adam(model_lstm.parameters())\n",
        "loss_func = nn.CrossEntropyLoss(ignore_index=token_to_idx['_'])\n",
        "history = []"
      ],
      "metadata": {
        "id": "sbaK48dH5THW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyEjsdKiC5dw"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "collapsed": true,
        "id": "ih7Va7PMC5dw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "757345f9-de54-4cf6-85be-1fd7ae73ac2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "for i in range(1000):\n",
        "    batch_ix = to_matrix(sample(sonnets, BATCH_LEN))\n",
        "    batch_ix = torch.LongTensor(batch_ix)\n",
        "    state = model_lstm.initial_state(BATCH_LEN)\n",
        "\n",
        "    state, logits_seq = model_lstm(batch_ix, state)\n",
        "    \n",
        "    #compute loss\n",
        "    predictions_logits = logits_seq[:, :-1]\n",
        "    actual_next_tokens = batch_ix[:, 1:]\n",
        "    loss = loss_func(predictions_logits.contiguous().view(-1, NUM_TOKENS), \n",
        "                     actual_next_tokens.contiguous().view(-1))\n",
        "    \n",
        "    # train with backprop\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    history.append(loss.data.numpy())\n",
        "    if (i+1)%100==0:\n",
        "      clear_output(True)\n",
        "      plt.plot(history,label='loss')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"LSTM didn't converge.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sample_lstm(rnn, seed_phrase='a', max_length=MAX_LEN, temperature=1.0):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The LSTM is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "    \n",
        "    x_sequence = [token_to_idx[token] for token in seed_phrase.lower()]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
        "    state = rnn.initial_state(batch_size=1)\n",
        "    \n",
        "    #feed the seed phrase, if any\n",
        "    state, logits_next = rnn(x_sequence, state)\n",
        "    \n",
        "    #start generating\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        state, logits_next = rnn(x_sequence[:, None, -1], state)\n",
        "        p_next = F.softmax(logits_next / temperature, dim=-1).data.numpy()[0]\n",
        "        \n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(num_tokens, p=p_next[0])\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "\n",
        "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
      ],
      "metadata": {
        "id": "XMOIWXEqSaMl"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whi9QVE9C5dw"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "collapsed": true,
        "id": "4-iHOy3-C5dw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f10fe163-8c55-4a2e-dd12-b059c50b55fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature=0.1:\n",
            "away;\n",
            "      o! love i see the painted on such a prove the stary steal,\n",
            "  which i say mind of thine eyes are seen,\n",
            "  which i say seem but will be all the self,\n",
            "    and there and the true in my self doth live,\n",
            "  and such a compored of thee thine own state,\n",
            "  and such my love shall thee that love to me,\n",
            "    and therefore mayst thy sweet self i love thee,\n",
            "  where thou art thou art to thee i am now,\n",
            "  when i have seen the world with me thou hast,\n",
            "  and say the stars and self i love thee tend,\n",
            "  when i self the present of thy shadows spend,\n",
            "  the wide thoughts in thee i am not so sore,\n",
            "    and the true thee art to the see the starte,\n",
            "  and therefore mayst thou this poor dear live,\n",
            "  and that which i think \n",
            "\n",
            "\n",
            "Temperature=0.2:\n",
            "away,\n",
            "      o! i how i have seen the take that thou dost be as thee,\n",
            "  when thou art thou art which that thou mayst call,\n",
            "    and that heaven that all the world in heart,\n",
            "  that i shall be the self in the state,\n",
            "  and me thou wilt, for thy self doth show,\n",
            "    then that thou art with thee thou art as all.\n",
            "  the lear the world may still the world of thy state,\n",
            "  and such my love, and there is but love's great,\n",
            "  the though the stars to thee i am forthen.\n",
            "  and will not be straight in the world thee dear,\n",
            "  which i sun in menting that love still,\n",
            "  that i say that i am not so some;\n",
            "    but then the self to the strong mine eyes,\n",
            "  the world thee thou art as false i do now.\n",
            "    so long i see thee, that i \n",
            "\n",
            "\n",
            "Temperature=0.5:\n",
            "away?\n",
            "      i am not i wor it the three ano my self in thee alone,\n",
            "  why such a part where is my sake of me, to truth;\n",
            "  and since your heart in thee i am and dear\n",
            "  find the world, and that which through in thee,\n",
            "    self thou art be so vice me to white,\n",
            "  and therefore made live in thy self i seen,\n",
            "  which thy self the present doth should love show,\n",
            "    that shall be thy wadds be of sovereit death,\n",
            "  and both her, and thee i would be all heart\n",
            "  and self thou art mad and self thou art prove\n",
            "  one to thee, in their love and some in thee,\n",
            "  when i love thee, and therefore my desert,\n",
            "  and beauty shall with true thee are so streng;\n",
            "  but when i self despite of slave to show,\n",
            "    there alter then len s\n",
            "\n",
            "\n",
            "Temperature=1.0:\n",
            "away\n",
            "    i all though platureal of sake i have robst care hold?\n",
            "  thou makes tans all are thee,\n",
            "    freced imble find a throw'd fair form amber:\n",
            "    o! yet thou art wearny of wastes dig\n",
            "  for, all my being a summer's pride:\n",
            "  not shully forinest have the painter gaken:\n",
            "  but pition thy wilter goring of my upen\n",
            "  to fearten where thenore fully delame,\n",
            "    save is that thou, muse componeds doth told?\n",
            "  have sworn, buld not conceated wateot,\n",
            "    whrice so ewesh tongueet to more crife all place:\n",
            "    but such,ed thee for stronk's behink at my deep:\n",
            "  thy self thy wand,--rine ay the renite look.\n",
            "    this own confounded on one gone, what shometh\n",
            "  and but fordun my judg each you wild with,\n",
            "  and heart tenkl\n",
            "\n",
            "\n",
            "Temperature=2.0:\n",
            "away.-lazczlahjjisucp_kilvink,n;--test,anten potw?rblaws,\n",
            "  my kiinzkings our rathis wortabers-o've:\n",
            "     his xold tit is, orr,iof-lorigunmqucass,\n",
            "  nocy coot lel fisted viery cruel;\n",
            "  nay awiequgund ghe inajullys tiquer\n",
            ",  it hoon legixz; forift) i'ffects do is heals?,\n",
            "  whath my ppsorn've-siode's, minestlalo's yeak.'n\n",
            "  than (hathprisers quzeped, creiking stombslyihid;\n",
            "  abuste o'archfts breefil!-postroy.ing quity,\n",
            "  sworgly nacg itjoum why knowatt foun:\n",
            "  manffredonblamen'd; ull it giqectidni\n",
            "  can allunden, tenury tougu\n",
            "  tu paybblogm desfecticgsion;\n",
            "  asty expleyer i, vriaku nigginy,\n",
            "  enti'stnesstim'uncusy dut stele;\n",
            "  i o thal'st hs exere high ge hearty\n",
            ",,'w whatewhesp caygbar sucker'd not.\n",
            "  \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "temp = [0.1, 0.2, 0.5, 1.0, 2.0]\n",
        "\n",
        "for t in temp:\n",
        "  poem = generate_sample_lstm(model_lstm, seed_phrase = 'away', temperature=t)\n",
        "  print('Temperature=%s:' % t)\n",
        "  print(poem)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6mdoSDMC5dx"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhH6mfbrC5dx"
      },
      "source": [
        "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "collapsed": true,
        "id": "3Ld5KeFuC5dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4259ecc8-db8e-4ab7-fa39-b9bf14b49be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to path ./model.pth\n"
          ]
        }
      ],
      "source": [
        "path = './model.pth'\n",
        "torch.save(model_lstm.state_dict(), path)\n",
        "print('Saving model to path %s' % path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "archieved_model = CharLSTMLoop(emb_size=64)\n",
        "archieved_model.load_state_dict(torch.load(path))\n",
        "archieved_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lossesrKG_fr",
        "outputId": "d0c92df9-d398-4440-9009-37257c24329b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharLSTMLoop(\n",
              "  (emb): Embedding(39, 64)\n",
              "  (lstm): LSTM(64, 256, batch_first=True)\n",
              "  (hid_to_logits): Linear(in_features=256, out_features=39, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sample_lstm(archieved_model, seed_phrase = 'away', temperature=1.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emK5BOimInLs",
        "outputId": "1f2e3a30-54ac-4d99-cd44-5a8c8601994b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "away..x?.  the drects on eyel knows white thought that love,\n",
            "  nor have posess from heich from their stains,\n",
            "  when thy prey of less' in thy true in pory\n",
            "  as with used from heart's grife in lee.\n",
            "  thins eye ming one offerides hounds unbainted;\n",
            "    and therefore than in her pone in thy amase;\n",
            "  some weceins, and thou myself idferanting,\n",
            "  when in the present cheke the losion me,\n",
            "  mure then that were that which excuse gone;\n",
            "  i say no teem'd the mayst thy did mide,\n",
            "    the oby night, ginds a diefur sing?\n",
            "  and one gone, i how my faire to muse,\n",
            "  and you came no, lich by deep show it thee:\n",
            "  but this wor, so ill the dost toncee,\n",
            "    hearts to perfect feeming me, my face so great,\n",
            "    turn'd muse which\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1vPfy5UC5dx"
      },
      "source": [
        "### References\n",
        "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "K83--qlSC5dm"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
